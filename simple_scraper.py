#!/usr/bin/env python3
"""
ğŸ¼ ê°„ë‹¨í•œ í´ë˜ì‹ ê³µì—° ì •ë³´ ìŠ¤í¬ë˜í¼ (Selenium ì—†ì´)
"""

import requests
from bs4 import BeautifulSoup
import re
import json
from datetime import datetime

class SimpleConcertScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })

    def get_page_content(self, url):
        """í˜ì´ì§€ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return None

    def extract_title(self, soup, text):
        """ê³µì—° ì œëª© ì¶”ì¶œ"""
        # ë¡¯ë°ì½˜ì„œíŠ¸í™€ íŠ¹ì • íŒ¨í„´
        title_patterns = [
            r'ì •ëª…í›ˆ\s*&\s*ì›\s*ì½”ë¦¬ì•„\s*ì˜¤ì¼€ìŠ¤íŠ¸ë¼\s*<[^>]+>',
            r'[ê°€-í£\w\s&,.]+<[ê°€-í£\w\s]+>',
            r'[ê°€-í£\w\s&,.]{10,100}'
        ]
        
        for pattern in title_patterns:
            match = re.search(pattern, text)
            if match:
                title = match.group().strip()
                if len(title) > 5 and not any(skip in title.lower() for skip in ['ê³µì—°ì •ë³´', 'lotte', 'sac', 'ì˜ˆë§¤']):
                    return title
        
        # HTML íƒœê·¸ì—ì„œ ì°¾ê¸°
        title_selectors = ['h1', 'title', '.concert_title', '.performance_title']
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element:
                title = element.get_text().strip()
                if len(title) > 5 and not any(skip in title.lower() for skip in ['ê³µì—°ì •ë³´', 'lotte', 'sac', 'ì˜ˆë§¤']):
                    return title
                    
        return "ì œëª© ì¶”ì¶œ ì‹¤íŒ¨"

    def extract_date_time(self, text):
        """ë‚ ì§œ ë° ì‹œê°„ ì¶”ì¶œ"""
        date_patterns = [
            r'2025[-\.]\d{1,2}[-\.]\d{1,2}\s*\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)\s*\d{1,2}:\d{2}',
            r'2025ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)\s*\d{1,2}:\d{2}',
            r'2025[-\.]\d{1,2}[-\.]\d{1,2}',
            r'2025ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                return match.group().strip()
                
        return ""

    def extract_venue(self, text):
        """ê³µì—°ì¥ ì¶”ì¶œ"""
        venues = [
            'ë¡¯ë°ì½˜ì„œíŠ¸í™€', 'ì˜ˆìˆ ì˜ì „ë‹¹', 'SAC', 'ì„¸ì¢…ë¬¸í™”íšŒê´€', 'í†µì˜êµ­ì œìŒì•…ë‹¹',
            'LGì•„íŠ¸ì„¼í„°', 'ê¸ˆí˜¸ì•„íŠ¸í™€', 'ë¸”ë£¨ìŠ¤í€˜ì–´', 'IBKì±”ë²„í™€', 'ë¦¬ì‚¬ì´í‹€í™€'
        ]
        
        for venue in venues:
            if venue in text:
                return venue
                    
        return ""

    def extract_performers(self, text):
        """ì¶œì—°ì§„ ì •ë³´ ì¶”ì¶œ"""
        performers = []
        
        # ë¡¯ë°ì½˜ì„œíŠ¸í™€ í˜•ì‹: "ì—­í•  | ì´ë¦„"
        role_patterns = [
            (r'ì§€íœ˜\s*[|â”‚]\s*([ê°€-í£\s]+(?:\([A-Za-z\s\-]+\))?)', 'ì§€íœ˜'),
            (r'ì†Œí”„ë¼ë…¸\s*[|â”‚]\s*([ê°€-í£\s]+(?:\([A-Za-z\s\-]+\))?)', 'ì†Œí”„ë¼ë…¸'),
            (r'ë©”ì¡°\s*ì†Œí”„ë¼ë…¸\s*[|â”‚]\s*([ê°€-í£\s]+(?:\([A-Za-z\s\-]+\))?)', 'ë©”ì¡°ì†Œí”„ë¼ë…¸'),
            (r'í…Œë„ˆ\s*[|â”‚]\s*([ê°€-í£\s]+(?:\([A-Za-z\s\-]+\))?)', 'í…Œë„ˆ'),
            (r'ë°”ë¦¬í†¤\s*[|â”‚]\s*([ê°€-í£\s]+(?:\([A-Za-z\s\-]+\))?)', 'ë°”ë¦¬í†¤'),
            (r'ì—°ì£¼\s*[|â”‚]\s*([ê°€-í£\s\w]+(?:\([A-Za-z\s\-]+\))?)', 'ì—°ì£¼'),
            (r'í•©ì°½\s*[|â”‚]\s*([ê°€-í£\s\w,]+)', 'í•©ì°½'),
        ]
        
        for pattern, role in role_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                name = match.group(1).strip()
                if name and len(name) > 1:
                    performer_info = f"{name} - {role}"
                    if performer_info not in performers:
                        performers.append(performer_info)
        
        return performers[:12]  # ìµœëŒ€ 12ëª…

    def extract_program(self, text):
        """í”„ë¡œê·¸ë¨ ì •ë³´ ì¶”ì¶œ"""
        programs = []
        
        # ë² í† ë²¤ êµí–¥ê³¡ ì œ9ë²ˆ íŠ¹ë³„ íŒ¨í„´
        beethoven_patterns = [
            r'ë² í† ë²¤\s*êµí–¥ê³¡\s*ì œ\s*9ë²ˆ[^\n]{0,50}',
            r'Beethoven\s*Symphony\s*No\.?\s*9[^\n]{0,50}',
            r'êµí–¥ê³¡\s*ì œ\s*9ë²ˆ[^\n]*(?:í•©ì°½|Choral)',
        ]
        
        for pattern in beethoven_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                program = match.group().strip()
                if program not in programs:
                    programs.append(program)
        
        # ì¼ë°˜ì ì¸ ì‘ê³¡ê°€ íŒ¨í„´
        composers = [
            'Rachmaninoff', 'Beethoven', 'Mozart', 'Bach', 'Brahms', 'Chopin', 
            'ë¼íë§ˆë‹ˆë…¸í”„', 'ë² í† ë²¤', 'ëª¨ì°¨ë¥´íŠ¸', 'ë°”í', 'ë¸ŒëŒìŠ¤', 'ì‡¼íŒ½'
        ]
        
        for composer in composers:
            pattern = rf'{composer}[^\n]{{10,80}}'
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                program = match.group().strip()
                if len(program) > 10 and len(program) < 120:
                    if not any(skip in program.lower() for skip in ['ê°€ê²©', 'price', 'í‹°ì¼“']) and program not in programs:
                        programs.append(program)
        
        return programs[:8]  # ìµœëŒ€ 8ê°œ

    def extract_price(self, text):
        """ê°€ê²© ì •ë³´ ì¶”ì¶œ"""
        prices = []
        
        # ì¢Œì„ë³„ ê°€ê²© íŒ¨í„´
        seat_patterns = [
            r'[RSABCVIP]+ì„\s*[:\s]*[\d,]+ì›',
            r'[RSABCVIP]+\s*[:\s]*[\d,]+ì›',
            r'ì‹œì•¼ë°©í•´[RSAB]*\s*[:\s]*[\d,]+ì›'
        ]
        
        for pattern in seat_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                price = match.group().strip()
                if price not in prices:
                    prices.append(price)
        
        return prices[:6]  # ìµœëŒ€ 6ê°œ ê°€ê²©

    def scrape_concert_info(self, url):
        """ê³µì—° ì •ë³´ ìŠ¤í¬ë˜í•‘"""
        print(f"ğŸ” ìŠ¤í¬ë˜í•‘ ì¤‘: {url}")
        
        html_content = self.get_page_content(url)
        if not html_content:
            return None
            
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ íƒœê·¸ ì œê±°
        for script in soup(["script", "style"]):
            script.decompose()
            
        text_content = soup.get_text()
        
        # ì •ë³´ ì¶”ì¶œ
        concert_info = {
            'url': url,
            'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'title': self.extract_title(soup, text_content),
            'date': self.extract_date_time(text_content),
            'venue': self.extract_venue(text_content),
            'performers': self.extract_performers(text_content),
            'program': self.extract_program(text_content),
            'price': self.extract_price(text_content)
        }
        
        return concert_info

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (Selenium ì—†ìœ¼ë¯€ë¡œ í•„ìš” ì—†ìŒ)"""
        pass