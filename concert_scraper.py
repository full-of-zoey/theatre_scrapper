#!/usr/bin/env python3
"""
ğŸ¼ í´ë˜ì‹ ê³µì—° ì •ë³´ ìŠ¤í¬ë˜í¼
ë¡¯ë°ì½˜ì„œíŠ¸í™€, ì˜ˆìˆ ì˜ì „ë‹¹ ë“±ì˜ ê³µì—° ì •ë³´ë¥¼ ì˜ˆì˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from rich.table import Table
from rich.prompt import Prompt
from rich import print as rprint
import re
import time
from datetime import datetime
import json

console = Console()

class ConcertScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        })
        self.driver = None

    def setup_driver(self):
        """Selenium WebDriver ì„¤ì •"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        service = Service(ChromeDriverManager().install())
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
    def get_page_content(self, url):
        """í˜ì´ì§€ ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° (Selenium + requests ì¡°í•©)"""
        try:
            # ë¨¼ì € requestsë¡œ ì‹œë„
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                return response.text
        except:
            pass
            
        # requests ì‹¤íŒ¨ì‹œ Selenium ì‚¬ìš©
        try:
            if not self.driver:
                self.setup_driver()
            
            self.driver.get(url)
            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            return self.driver.page_source
        except Exception as e:
            console.print(f"[red]í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return None

    def extract_title(self, soup, text):
        """ê³µì—° ì œëª© ì¶”ì¶œ"""
        title_patterns = [
            r'ì •ëª…í›ˆ\s*&\s*ì›\s*ì½”ë¦¬ì•„\s*ì˜¤ì¼€ìŠ¤íŠ¸ë¼\s*<[^>]+>',
            r'[^<>\n]{5,100}<[^<>\n]+>',
            r'[ê°€-í£\s\w&,\.]{5,100}'
        ]
        
        # í…ìŠ¤íŠ¸ì—ì„œ íŒ¨í„´ ë§¤ì¹­
        for pattern in title_patterns:
            match = re.search(pattern, text)
            if match:
                title = match.group().strip()
                if len(title) > 5:
                    return title
        
        # HTML íƒœê·¸ì—ì„œ ì°¾ê¸°
        title_selectors = ['h1', '.concert_title', '.performance_title', 'title']
        for selector in title_selectors:
            element = soup.select_one(selector)
            if element and element.get_text().strip():
                title = element.get_text().strip()
                if len(title) > 5 and 'ê³µì—°ì •ë³´' not in title:
                    return title
                    
        return "ì œëª© ì—†ìŒ"

    def extract_date_time(self, text):
        """ë‚ ì§œ ë° ì‹œê°„ ì¶”ì¶œ"""
        date_patterns = [
            r'\d{4}[-\.]\d{1,2}[-\.]\d{1,2}\s*\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)\s*\d{1,2}:\d{2}',
            r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼\s*\([ì›”í™”ìˆ˜ëª©ê¸ˆí† ì¼]\)\s*\d{1,2}:\d{2}',
            r'\d{4}[-\.]\d{1,2}[-\.]\d{1,2}',
            r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                return match.group().strip()
                
        return ""

    def extract_venue(self, text):
        """ê³µì—°ì¥ ì¶”ì¶œ"""
        venues = [
            'ë¡¯ë°ì½˜ì„œíŠ¸í™€', 'ì˜ˆìˆ ì˜ì „ë‹¹', 'SAC', 'ì„¸ì¢…ë¬¸í™”íšŒê´€', 'í†µì˜êµ­ì œìŒì•…ë‹¹',
            'LGì•„íŠ¸ì„¼í„°', 'ê¸ˆí˜¸ì•„íŠ¸í™€', 'ë¸”ë£¨ìŠ¤í€˜ì–´', 'IBKì±”ë²„í™€', 'ë¦¬ì‚¬ì´í‹€í™€'
        ]
        
        for venue in venues:
            if venue in text:
                # ì£¼ë³€ í…ìŠ¤íŠ¸ë„ í•¨ê»˜ ì¶”ì¶œ
                pattern = rf'{venue}[^\n]{{0,30}}'
                match = re.search(pattern, text)
                if match:
                    return match.group().strip()
                    
        return ""

    def extract_performers(self, text):
        """ì¶œì—°ì§„ ì •ë³´ ì¶”ì¶œ"""
        performers = []
        
        # ë¡¯ë°ì½˜ì„œíŠ¸í™€ í˜•ì‹: "ì—­í•  | ì´ë¦„"
        role_patterns = [
            (r'ì§€íœ˜\s*[|â”‚]\s*([^\n,]+)', 'ì§€íœ˜'),
            (r'ì†Œí”„ë¼ë…¸\s*[|â”‚]\s*([^\n,]+)', 'ì†Œí”„ë¼ë…¸'),
            (r'ë©”ì¡°\s*ì†Œí”„ë¼ë…¸\s*[|â”‚]\s*([^\n,]+)', 'ë©”ì¡°ì†Œí”„ë¼ë…¸'),
            (r'í…Œë„ˆ\s*[|â”‚]\s*([^\n,]+)', 'í…Œë„ˆ'),
            (r'ë°”ë¦¬í†¤\s*[|â”‚]\s*([^\n,]+)', 'ë°”ë¦¬í†¤'),
            (r'ì—°ì£¼\s*[|â”‚]\s*([^\n,]+)', 'ì—°ì£¼'),
            (r'í•©ì°½\s*[|â”‚]\s*([^\n,]+)', 'í•©ì°½'),
            (r'í”¼ì•„ë…¸\s*[|â”‚]\s*([^\n,]+)', 'í”¼ì•„ë…¸'),
            (r'ë°”ì´ì˜¬ë¦°\s*[|â”‚]\s*([^\n,]+)', 'ë°”ì´ì˜¬ë¦°')
        ]
        
        for pattern, role in role_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                name = match.group(1).strip()
                if name and len(name) > 1:
                    # í•œê¸€/ì˜ë¬¸ ì´ë¦„ ë¶„ë¦¬
                    name_match = re.search(r'([\ê°€-í£\s]+)\s*([A-Za-z\s\-]+)?', name)
                    if name_match:
                        kor_name = name_match.group(1).strip()
                        eng_name = name_match.group(2).strip() if name_match.group(2) else ""
                        
                        if eng_name:
                            full_name = f"{kor_name} ({eng_name})"
                        else:
                            full_name = kor_name
                            
                        performer_info = f"{full_name} - {role}"
                        if performer_info not in performers:
                            performers.append(performer_info)
        
        # ì¼ë°˜ì ì¸ ì¶œì—°ì§„ íŒ¨í„´
        general_patterns = [
            r'ì¶œì—°\s*[:\s]*([^\n]+)',
            r'ì—°ì£¼ì\s*[:\s]*([^\n]+)'
        ]
        
        for pattern in general_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                names = match.group(1).split(',')
                for name in names:
                    name = name.strip()
                    if name and len(name) > 1 and name not in [p.split(' - ')[0] for p in performers]:
                        performers.append(name)
        
        return performers[:15]  # ìµœëŒ€ 15ëª…

    def extract_program(self, text):
        """í”„ë¡œê·¸ë¨ ì •ë³´ ì¶”ì¶œ"""
        programs = []
        
        # ë² í† ë²¤ êµí–¥ê³¡ ì œ9ë²ˆ íŠ¹ë³„ íŒ¨í„´
        beethoven_patterns = [
            r'ë² í† ë²¤\s*êµí–¥ê³¡\s*ì œ\s*9ë²ˆ[^\n]{0,50}',
            r'Beethoven\s*Symphony\s*No\.?\s*9[^\n]{0,50}',
            r'êµí–¥ê³¡\s*ì œ\s*9ë²ˆ[^\n]*(?:í•©ì°½|Choral)',
            r'ë² í† ë²¤[^\n]{0,30}(?:dë‹¨ì¡°|D\s*minor)[^\n]{0,30}(?:op\.?\s*125|Op\.?\s*125)'
        ]
        
        for pattern in beethoven_patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                program = match.group().strip()
                if program not in programs:
                    programs.append(program)
        
        # ì¼ë°˜ì ì¸ ì‘ê³¡ê°€ íŒ¨í„´
        composers = [
            'Bach', 'Mozart', 'Beethoven', 'Brahms', 'Chopin', 'Schubert', 
            'Rachmaninoff', 'Tchaikovsky', 'Mahler', 'Debussy', 'Ravel',
            'ë°”í', 'ëª¨ì°¨ë¥´íŠ¸', 'ë² í† ë²¤', 'ë¸ŒëŒìŠ¤', 'ì‡¼íŒ½', 'ìŠˆë² ë¥´íŠ¸', 'ì°¨ì´ì½¥ìŠ¤í‚¤'
        ]
        
        for composer in composers:
            pattern = rf'{composer}[^\n]{{5,100}}'
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                program = match.group().strip()
                if len(program) > 10 and len(program) < 150:
                    if not any(p in program.lower() for p in ['ê°€ê²©', 'price', 'í‹°ì¼“', 'ticket']) and program not in programs:
                        programs.append(program)
        
        return programs[:10]  # ìµœëŒ€ 10ê°œ

    def extract_price(self, text):
        """ê°€ê²© ì •ë³´ ì¶”ì¶œ"""
        prices = []
        
        # ì¢Œì„ë³„ ê°€ê²© íŒ¨í„´
        seat_patterns = [
            r'[RSABCVIP]+ì„\s*[:\s]*[\d,]+ì›',
            r'[RSABCVIP]+\s*[:\s]*[\d,]+ì›',
            r'(?:ì „ì„|ì¼ë°˜|í•™ìƒ)\s*[:\s]*[\d,]+ì›',
            r'ì‹œì•¼ë°©í•´[RSAB]*\s*[:\s]*[\d,]+ì›'
        ]
        
        for pattern in seat_patterns:
            matches = re.finditer(pattern, text)
            for match in matches:
                price = match.group().strip()
                if price not in prices:
                    prices.append(price)
        
        # ì¼ë°˜ ê°€ê²© íŒ¨í„´ (ì¢Œì„ë³„ì´ ì—†ì„ ë•Œ)
        if not prices:
            general_patterns = [r'[\d,]+ì›']
            for pattern in general_patterns:
                matches = re.finditer(pattern, text)
                for match in matches:
                    price_str = match.group().strip()
                    # ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ í•©ë¦¬ì ì¸ ë²”ìœ„ì¸ì§€ í™•ì¸
                    price_num = int(re.sub(r'[^\d]', '', price_str))
                    if 1000 <= price_num <= 1000000:  # 1ì²œì›~100ë§Œì›
                        if price_str not in prices:
                            prices.append(price_str)
        
        return prices[:8]  # ìµœëŒ€ 8ê°œ ê°€ê²©

    def scrape_concert_info(self, url):
        """ê³µì—° ì •ë³´ ìŠ¤í¬ë˜í•‘"""
        console.print(f"[cyan]ğŸ” ìŠ¤í¬ë˜í•‘ ì¤‘: {url}")
        
        html_content = self.get_page_content(url)
        if not html_content:
            return None
            
        soup = BeautifulSoup(html_content, 'html.parser')
        text_content = soup.get_text()
        
        # ì •ë³´ ì¶”ì¶œ
        concert_info = {
            'url': url,
            'scraped_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'title': self.extract_title(soup, text_content),
            'date': self.extract_date_time(text_content),
            'venue': self.extract_venue(text_content),
            'performers': self.extract_performers(text_content),
            'program': self.extract_program(text_content),
            'price': self.extract_price(text_content)
        }
        
        return concert_info

    def display_concert_info(self, info):
        """ê³µì—° ì •ë³´ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥"""
        if not info:
            console.print("[red]âŒ ê³µì—° ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        # ì œëª©
        title_text = Text(info['title'], style="bold magenta")
        title_panel = Panel(title_text, title="ğŸ¼ ê³µì—° ì œëª©", border_style="magenta")
        console.print(title_panel)
        console.print()
        
        # ì •ë³´ í…Œì´ë¸”
        table = Table(show_header=True, header_style="bold blue", border_style="blue")
        table.add_column("í•­ëª©", style="cyan", width=15)
        table.add_column("ë‚´ìš©", style="white")
        
        # ë‚ ì§œ ë° ì‹œê°„
        if info['date']:
            table.add_row("ğŸ“… ë‚ ì§œ/ì‹œê°„", info['date'])
        
        # ê³µì—°ì¥
        if info['venue']:
            table.add_row("ğŸ›ï¸ ê³µì—°ì¥", info['venue'])
        
        # ì¶œì—°ì§„
        if info['performers']:
            performers_text = '\n'.join(info['performers'][:8])  # ìµœëŒ€ 8ëª…
            if len(info['performers']) > 8:
                performers_text += f"\n... ì™¸ {len(info['performers']) - 8}ëª…"
            table.add_row("ğŸ‘¥ ì¶œì—°ì§„", performers_text)
        
        # í”„ë¡œê·¸ë¨
        if info['program']:
            program_text = '\n'.join(info['program'])
            table.add_row("ğŸµ í”„ë¡œê·¸ë¨", program_text)
        
        # ê°€ê²©
        if info['price']:
            price_text = '\n'.join(info['price'])
            table.add_row("ğŸ’° ê°€ê²©", price_text)
        
        # URL
        table.add_row("ğŸ”— URL", info['url'])
        
        # ìŠ¤í¬ë˜í•‘ ì‹œê°„
        table.add_row("â° ìˆ˜ì§‘ì‹œê°„", info['scraped_at'])
        
        console.print(table)
        console.print()

    def save_to_json(self, info, filename=None):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"concert_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(info, f, ensure_ascii=False, indent=2)
            console.print(f"[green]ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
        except Exception as e:
            console.print(f"[red]âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")

    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.driver:
            self.driver.quit()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    console.print(Panel.fit(
        "[bold magenta]ğŸ¼ í´ë˜ì‹ ê³µì—° ì •ë³´ ìŠ¤í¬ë˜í¼[/bold magenta]\n"
        "[cyan]ë¡¯ë°ì½˜ì„œíŠ¸í™€, ì˜ˆìˆ ì˜ì „ë‹¹ ë“±ì˜ ê³µì—° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.[/cyan]",
        border_style="magenta"
    ))
    console.print()
    
    scraper = ConcertScraper()
    
    try:
        while True:
            # URL ì…ë ¥
            url = Prompt.ask(
                "[cyan]ğŸ”— ê³µì—° ì •ë³´ URLì„ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: quit)[/cyan]",
                default="https://www.lotteconcerthall.com/kor/Performance/ConcertDetails/260852"
            )
            
            if url.lower() in ['quit', 'exit', 'q']:
                break
            
            if not url.startswith('http'):
                console.print("[red]âŒ ì˜¬ë°”ë¥¸ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            
            # ìŠ¤í¬ë˜í•‘ ì‹¤í–‰
            console.print()
            with console.status("[cyan]ìŠ¤í¬ë˜í•‘ ì¤‘...", spinner="dots"):
                concert_info = scraper.scrape_concert_info(url)
            
            # ê²°ê³¼ ì¶œë ¥
            scraper.display_concert_info(concert_info)
            
            # ì €ì¥ ì—¬ë¶€ í™•ì¸
            if concert_info:
                save = Prompt.ask("[cyan]JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n)[/cyan]", default="n")
                if save.lower() in ['y', 'yes']:
                    scraper.save_to_json(concert_info)
            
            console.print("\n" + "="*60 + "\n")
            
    except KeyboardInterrupt:
        console.print("\n[yellow]ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    finally:
        scraper.close()


if __name__ == "__main__":
    main()